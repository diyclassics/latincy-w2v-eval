# Latin Odd-One-Out Evaluation

Total tasks: 2728
Tasks solved by at least one model: 2179
Tasks not solved by any model: 549

## Accuracy Summary

| Model | Accuracy | Correct |
| --- | --- | --- |
| latincy_w2v-CBOW-100-10-0_0_2 | 0.626 | 1707 |
| latincy_w2v-CBOW-100-5-0_0_2 | 0.642 | 1751 |
| latincy_w2v-CBOW-300-10-0_0_2 | 0.666 | 1817 |
| latincy_w2v-CBOW-300-5-0_0_2 | **0.667** | 1820 |
| latincy_w2v-CBOW-50-10-0_0_2 | 0.620 | 1691 |
| latincy_w2v-CBOW-50-5-0_0_2 | 0.613 | 1671 |
| latincy_w2v-SG-100-10-0_0_2 | 0.543 | 1482 |
| latincy_w2v-SG-100-5-0_0_2 | 0.556 | 1518 |
| latincy_w2v-SG-300-10-0_0_2 | 0.562 | 1534 |
| latincy_w2v-SG-300-5-0_0_2 | 0.577 | 1575 |
| latincy_w2v-SG-50-10-0_0_2 | 0.549 | 1499 |
| latincy_w2v-SG-50-5-0_0_2 | 0.560 | 1528 |
